{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryTextClassificationUsingRNN/LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0yiGWH7vb3VsgRBtwhtJb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4NyMi55xWU-",
        "colab_type": "text"
      },
      "source": [
        "#Binary Text Classification using RNN and LSTM\n",
        "##Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wsho0PPmC_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3_ZmahOok-D",
        "colab_type": "code",
        "outputId": "a5bea059-cfc2-4717-bf85-e6d3ef5a16a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF48Jah6rR22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXGiBdgprpc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "39c1063f-3520-48cd-85da-51ef93f88a4d"
      },
      "source": [
        "data = data.rename(index = str, columns = {'v1' : 'labels', 'v2' : 'text'})\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels                                               text\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU6SZuo7wFOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.2, random_state=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxR-_F8Gweq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "6b61900e-f0e1-4e5e-9a37-c1ec486c1122"
      },
      "source": [
        "train.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     labels                                               text\n",
              " 0      spam  XXXMobileMovieClub: To use your credit, click ...\n",
              " 1       ham               I tot u reach liao. He said t-shirt.\n",
              " 2       ham           K..k...from tomorrow onwards started ah?\n",
              " 3       ham  My uncles in Atlanta. Wish you guys a great se...\n",
              " 4       ham      I love your ass! Do you enjoy doggy style? :)\n",
              " ...     ...                                                ...\n",
              " 4452    ham                   HELLO PEACH! MY CAKE TASTS LUSH!\n",
              " 4453    ham                Still i have not checked it da. . .\n",
              " 4454    ham      Oh yeah! And my diet just flew out the window\n",
              " 4455    ham                        Sounds good, keep me posted\n",
              " 4456    ham  Yeah we wouldn't leave for an hour at least, h...\n",
              " \n",
              " [4457 rows x 2 columns],\n",
              "      labels                                               text\n",
              " 0       ham  C movie is juz last minute decision mah. Juz w...\n",
              " 1      spam  Show ur colours! Euro 2004 2-4-1 Offer! Get an...\n",
              " 2       ham             Dont let studying stress you out. L8r.\n",
              " 3       ham  Merry Christmas to you too babe, i love ya *ki...\n",
              " 4       ham                 Why did I wake up on my own &gt;:(\n",
              " ...     ...                                                ...\n",
              " 1110    ham  He's in lag. That's just the sad part but we k...\n",
              " 1111    ham  Good. do you think you could send me some pix?...\n",
              " 1112    ham                    We confirm eating at esplanade?\n",
              " 1113    ham                   Why i come in between you people\n",
              " 1114    ham                               Who u talking about?\n",
              " \n",
              " [1115 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubZzCg5_wuzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('train.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYCgjzP7xanP",
        "colab_type": "text"
      },
      "source": [
        "#Using torchtext to process the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WaVQHjZxGNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchtext as tt\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpzdHTXvx3B2",
        "colab_type": "text"
      },
      "source": [
        "Now, using `nltk` 'punkt' tokenizer, the words are tokenized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QySXNN5KxuC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5f5779fb-5aea-4d2f-85a0-4da4b72451b6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81x5NkKHyVIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = tt.data.Field(tokenize=word_tokenize)\n",
        "LABEL = tt.data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HOfnrHVyulI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafields = [(\"labels\", LABEL), (\"text\", TEXT)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fY23ezjy-Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn, tst = tt.data.TabularDataset.splits(path = '/content',\n",
        "                                         train = 'train.csv',\n",
        "                                         test = 'test.csv',\n",
        "                                         format = 'csv',\n",
        "                                         skip_header = True,\n",
        "                                         fields = datafields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsrOoeamz1tM",
        "colab_type": "text"
      },
      "source": [
        "Illustrating that the tabular csv data has now been transformed into objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4UOrf-bzg7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "3f951248-5a3b-4a4a-e5a6-b89d60f6ab43"
      },
      "source": [
        "trn[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<torchtext.data.example.Example at 0x7f32423d0f98>,\n",
              " <torchtext.data.example.Example at 0x7f32423d1be0>,\n",
              " <torchtext.data.example.Example at 0x7f32422c2550>,\n",
              " <torchtext.data.example.Example at 0x7f32422c26a0>,\n",
              " <torchtext.data.example.Example at 0x7f32422c2b38>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKCfGZ5gz0wa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b205b2c0-e78a-44e4-b963-3957fa39d94b"
      },
      "source": [
        "trn[0].__dict__.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['labels', 'text'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U9NQ4z70QZr",
        "colab_type": "text"
      },
      "source": [
        "The text has now been tokenized into individual words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpDcjgF00EyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "2d2e198f-d6e0-4ffe-fb86-5d16d38fe868"
      },
      "source": [
        "trn[0].text"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['XXXMobileMovieClub',\n",
              " ':',\n",
              " 'To',\n",
              " 'use',\n",
              " 'your',\n",
              " 'credit',\n",
              " ',',\n",
              " 'click',\n",
              " 'the',\n",
              " 'WAP',\n",
              " 'link',\n",
              " 'in',\n",
              " 'the',\n",
              " 'next',\n",
              " 'txt',\n",
              " 'message',\n",
              " 'or',\n",
              " 'click',\n",
              " 'here',\n",
              " '>',\n",
              " '>',\n",
              " 'http',\n",
              " ':',\n",
              " '//wap',\n",
              " '.',\n",
              " 'xxxmobilemovieclub.com',\n",
              " '?',\n",
              " 'n=QJKGIGHJJGCBL']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8-_NVsi0MAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a294f8ff-2268-4968-f9a5-a9843ebf9d70"
      },
      "source": [
        "print(vars(trn.examples[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'labels': 'spam', 'text': ['XXXMobileMovieClub', ':', 'To', 'use', 'your', 'credit', ',', 'click', 'the', 'WAP', 'link', 'in', 'the', 'next', 'txt', 'message', 'or', 'click', 'here', '>', '>', 'http', ':', '//wap', '.', 'xxxmobilemovieclub.com', '?', 'n=QJKGIGHJJGCBL']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFYerR_0tDe",
        "colab_type": "text"
      },
      "source": [
        "Now building a vocabulary using one-hot encoding, limiting the size of our feature vectors to 15000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKz2_BOb0imV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(trn, max_size = 15000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7tGqMwd1QSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(trn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OGvOYB01Ur7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "307b3a97-1a24-40a2-8938-9fee58a02252"
      },
      "source": [
        "print(f\"Unique tokens in TEXT & LABEL vocabs are as follows respectively: {len(TEXT.vocab)} & {len(LABEL.vocab)}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT & LABEL vocabs are as follows respectively: 10615 & 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkU7QTwN1yAY",
        "colab_type": "text"
      },
      "source": [
        "The number of unique tokens for TEXT are less than 15000, which shows that there are only 10613 unique tokens in `trn` dataset. Why 10613? The rest two are unk and pad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNz6D6QZ1sh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (trn, tst),\n",
        "    batch_size = batch_size,\n",
        "    sort_key = lambda x : len(x.text),\n",
        "    sort_within_batch = False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49hCbIKY3mWc",
        "colab_type": "text"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoiDFrfJ5EgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryNor3ZW3YM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, inp, embed, hid, out):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(inp, embed)\n",
        "    self.rnn = nn.RNN(embed, hid)\n",
        "    self.fc = nn.Linear(hid, out)\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, hidden = self.rnn(embedded)\n",
        "    hidden_1D = hidden.squeeze(0)\n",
        "    assert torch.equal(output[-1, :, :], hidden_1D)\n",
        "    return self.fc(hidden_1D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JctpBbf86DQt",
        "colab_type": "text"
      },
      "source": [
        "##Training the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R32pl6yU5Cwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = len(TEXT.vocab)\n",
        "embed = 100\n",
        "hid = 256\n",
        "out = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYEX9B_r6bRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(inp, embed, hid, out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GvkOc0d62o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci0OIRon7Cnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrl9hl-a7HXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.labels)\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (rounded_preds == batch.labels).float()\n",
        "\n",
        "    acc  = correct.sum() / len(correct)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvMdHZ0j8gBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "55557431-287a-411c-85ee-dbf091786bfc"
      },
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "  print(f'| epoch: {epoch+1:02} | train loss: {train_loss: .3f} | train acc: {train_acc*100:.2f}%')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch: 01 | train loss:  0.541 | train acc: 86.05%\n",
            "| epoch: 02 | train loss:  0.524 | train acc: 86.03%\n",
            "| epoch: 03 | train loss:  0.507 | train acc: 86.15%\n",
            "| epoch: 04 | train loss:  0.493 | train acc: 86.15%\n",
            "| epoch: 05 | train loss:  0.480 | train acc: 86.16%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwY2oapi9to6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_loss = 0\n",
        "epoch_acc = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZCRZiZo-co_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "71f1e245-68be-4639-f06d-37426aa1ce1e"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(10615, 100)\n",
              "  (rnn): RNN(100, 256)\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3POF1gT-gzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abca1a47-670f-4699-c9f5-018ea4ac04af"
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  for batch in test_iterator:\n",
        "  \n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "  \n",
        "    loss = criterion(predictions, batch.labels)\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (rounded_preds == batch.labels).float()\n",
        "\n",
        "    acc  = correct.sum() / len(correct)\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "test_acc = epoch_acc / len(test_iterator)\n",
        "print(f'| test loss: {test_loss: .3f} | test acc: {test_acc * 100: .2f}% |')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| test loss:  0.590 | test acc:  78.91% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PqPq0wPBd79",
        "colab_type": "text"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QiyFi57_v3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, inp, embed, hid, out):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(inp, embed)\n",
        "    self.rnn = nn.LSTM(embed, hid)\n",
        "    self.fc = nn.Linear(hid, out)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    embedded_dropout = self.dropout(embedded)\n",
        "    output, (hidden, _) = self.rnn(embedded_dropout)\n",
        "    hidden_1D = hidden.squeeze(0)\n",
        "    assert torch.equal(output[-1, :, :], hidden_1D)\n",
        "    return self.fc(hidden_1D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVV76LaMB94E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = len(TEXT.vocab)\n",
        "embed = 100\n",
        "hid = 256\n",
        "out = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kwKKHsZCZDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(inp, embed, hid, out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArUnzGBLCg61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9at-hR3HCmXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ZL08TSCprv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.labels)\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (rounded_preds == batch.labels).float()\n",
        "\n",
        "    acc  = correct.sum() / len(correct)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnuVgZ0lCyma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "9c8f5bfa-9396-4335-d8fb-b4e7f37d82dd"
      },
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "  print(f'| epoch: {epoch+1:02} | train loss: {train_loss: .3f} | train acc: {train_acc*100:.2f}%')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch: 01 | train loss:  0.670 | train acc: 85.56%\n",
            "| epoch: 02 | train loss:  0.658 | train acc: 86.40%\n",
            "| epoch: 03 | train loss:  0.646 | train acc: 86.33%\n",
            "| epoch: 04 | train loss:  0.636 | train acc: 86.31%\n",
            "| epoch: 05 | train loss:  0.625 | train acc: 86.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVoBoX35Cz3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_loss = 0\n",
        "epoch_acc = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRcNVhEwC4RE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "7b705f4e-32c5-4955-d574-11b091d631f1"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(10615, 100)\n",
              "  (rnn): LSTM(100, 256)\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWhPiUu_DBFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea6f5407-b470-49fd-b201-eb47ca254e5f"
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  for batch in test_iterator:\n",
        "  \n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "  \n",
        "    loss = criterion(predictions, batch.labels)\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (rounded_preds == batch.labels).float()\n",
        "\n",
        "    acc  = correct.sum() / len(correct)\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "test_acc = epoch_acc / len(test_iterator)\n",
        "print(f'| test loss: {test_loss: .3f} | test acc: {test_acc * 100: .2f}% |')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| test loss:  0.659 | test acc:  81.13% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUQBoFWbD4H-",
        "colab_type": "text"
      },
      "source": [
        "The LSTM implementation helped increase model accuracy, some of which was compensated by accuracy decrese due to the dropout used to prevent over-fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN3WnVlEDgJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}